import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import pickle
import sys
import argparse
import seaborn

parser = argparse.ArgumentParser()
parser.add_argument('input_file',
                    help='Pickle file generated by datoin_get_crawlstats.py')
parser.add_argument('output_file', nargs='?', default=None,
                    help='PDF file for output. If omitted, plots are shown '
                    'on the screen.')
args = parser.parse_args()

inputfilename = args.input_file
outputfilename = args.output_file

with open(inputfilename, 'rb') as pclfile:
    obj = pickle.load(pclfile)

from_date = obj['from_date']
index_hist = obj['index_hist']
crawl_hist = obj['crawl_hist']
delay_hist = obj['delay_hist']

pdf = None
if outputfilename:
    pdf = PdfPages(outputfilename)

index_hist.plot(xconvert=lambda x: from_date + x, drawstyle='steps',
               label='indexed')
crawl_hist.plot(xconvert=lambda x: from_date + x, drawstyle='steps',
               label='crawled')
plt.xticks(rotation=20)
plt.xlabel('date')
plt.ylabel('LinkedIn profiles')
plt.legend(loc='lower right')
plt.subplots_adjust(bottom=0.15)
if pdf:
    pdf.savefig()
    plt.close()
else:
    plt.show()

delay_hist.plot(drawstyle='steps')
plt.xlabel('delay [days]')
plt.ylabel('LinkedIn profiles')
if pdf:
    pdf.savefig()
    plt.close()
else:
    plt.show()


if pdf:
    pdf.close()
